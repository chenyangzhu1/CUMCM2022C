    \textbf{\songti{纹饰和风化类型统计}}
    \begin{lstlisting}[language=python]
import pandas as pd

data = pd.read_excel("附件.xlsx", sheet_name="表单1")
data = data.values
a = 0  # 无风化 a
b = 0  # 无风化 b
c = 0  # 无风化 c
d = 0  # 风化 a
e = 0  # 风化 b
f = 0  # 风化 c

for i in range(data.shape[0]):
    if (data[i, 4] == "无风化" and data[i, 1] == "A"):
        a += 1
    elif (data[i, 4] == "无风化" and data[i, 1] == "B"):
        b += 1
    elif (data[i, 4] == "无风化" and data[i, 1] == "C"):
        c += 1
    elif(data[i, 4] == "风化" and data[i, 1] == "A"):
        d += 1
    elif(data[i, 4] == "风化" and data[i, 1] == "B"):
        e+=1
    else:
        f+=1

    \end{lstlisting}

    \textbf{\songti{纹饰和风化卡方检验}}
    \begin{lstlisting}[language=python]
import math

import numpy as np
import pandas as pd
import scipy.stats as stats

table = np.zeros([3, 2])
table[0, 0] = 11
table[0, 1] = 11
table[1, 0] = 0
table[1, 1] = 6
table[2, 0] = 13
table[2, 1] = 17

kafang, p, ziyoudu, pingshubiao = stats.chi2_contingency(table)

xinagguanxishu = math.sqrt(kafang / (kafang + 58))
print("卡方值", kafang)
print("p值", p)
print("自由度", ziyoudu)
print("频数表", pingshubiao)
print("相关系数", xinagguanxishu)

    \end{lstlisting}


    \textbf{\songti{RankBiserial秩相关分析与气泡图绘制}}
    \begin{lstlisting}[language=python]
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy import stats

data = pd.read_excel("颜色排序.xlsx")
data = data.values

x = data[:, 4]
y = data[:, 3]

# print(stats.pointbiserialr(x, y))
# y是颜色
# x是二值


mydata = {'x': y, 'y': x}

df=pd.DataFrame(mydata)
my_mean=df.groupby('y')['x'].mean()

r_pb = 2*(my_mean[1]-my_mean[0])/(df.shape[0])

print(r_pb)

plotx = np.array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
ploty = np.array([1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 7, 8])
z = np.zeros(13)

for i in range(54):
    if (x[i] == 0 and y[i] == 1):
        z[0] += 1
    elif (x[i] == 0 and y[i] == 2):
        z[1] += 1
    elif (x[i] == 0 and y[i] == 3):
        z[2] += 1
    elif (x[i] == 0 and y[i] == 4):
        z[3] += 1
    elif (x[i] == 0 and y[i] == 5):
        z[4] += 1
    elif (x[i] == 0 and y[i] == 6):
        z[5] += 1
    elif (x[i] == 0 and y[i] == 7):
        z[6] += 1
    elif (x[i] == 1 and y[i] == 1):
        z[7] += 1
    elif (x[i] == 1 and y[i] == 3):
        z[8] += 1
    elif (x[i] == 1 and y[i] == 4):
        z[9] += 1
    elif (x[i] == 1 and y[i] == 5):
        z[10] += 1
    elif (x[i] == 1 and y[i] == 7):
        z[11] += 1
    elif (x[i] == 1 and y[i] == 8):
        z[12] += 1
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

plt.xlabel('表面是否风化（0为无风化，1为风化）', fontsize=13)
plt.ylabel('颜色（从1至8依次加深）', fontsize=13)

plt.scatter(plotx, ploty, s=250 * z, alpha=0.5)
plt.xlim(-1, 2)
plt.ylim(0, 9)
plt.show()


    \end{lstlisting}



    \textbf{\songti{第一问第二小问二氧化硅多因素方差分析}}
    \begin{lstlisting}[language=python]
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy
import scipy.stats as stats
from statsmodels.stats.anova import anova_lm
from statsmodels.formula.api import ols
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import statsmodels as sm

data = pd.read_excel("表1表2整合.xlsx")

data = data.values

a = 12  # 无风化 高钾
b = 23  # 无风化 铅钡
c = 6  # 风化 高钾
d = 26  # 风化 铅钡

alist = [0, 2, 3, 4, 5, 6, 7, 15, 16, 17, 18, 21]
blist = [20, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 39, 44, 45, 48, 49, 50, 51, 54, 56, 60, 63]
clist = [8, 11, 12, 14, 22, 28]
dlist = [1, 9, 10, 13, 19, 26, 27, 36, 38, 40, 41, 42, 43, 46, 47, 52, 53, 55, 57, 58, 59, 61, 62, 64, 65, 66]
#
# for i in range(data.shape[0]):
#     if(data[i,16]=="无风化" and data[i,18]=="高钾"):
#         a+=1
#         alist.append(i)
#     elif(data[i,16]=="无风化" and data[i,18]=="铅钡"):
#         b+=1
#         blist.append(i)
#     elif(data[i,16]=="风化" and data[i,18]=="高钾"):
#         c+=1
#         clist.append(i)
#     else:
#         d+=1
#         dlist.append(i)

ya = np.zeros(a)
yb = np.zeros(b)
yc = np.zeros(c)
yd = np.zeros(d)

idx = 1

for i in range(a):
    ya[i] = data[alist[i], idx]

for i in range(b):
    yb[i] = data[blist[i], idx]

for i in range(c):
    yc[i] = data[clist[i], idx]

for i in range(d):
    yd[i] = data[dlist[i], idx]

ya = np.sort(ya)
yb = np.sort(yb)
yc = np.sort(yc)
yd = np.sort(yd)


def self_JBtest(y):
    # 样本规模n
    n = y.size
    # for i in range(data.shape[0]):
    #     if(data[i,16]=="无风化"):
    #         n+=1
    y_ = y - y.mean()
    M2 = np.mean(y_ ** 2)

    skew = np.mean(y_ ** 3) / M2 ** 1.5
    krut = np.mean(y_ ** 4) / M2 ** 2

    #         wufenglist.append(i)
    #     else:
    #         m+=1
    #         fenglist.append(i)
    JB = n * (skew ** 2 / 6 + (krut - 3) ** 2 / 24)
    pvalue = 1 - stats.chi2.cdf(JB, df=2)
    print("JB检验：", stats.jarque_bera(y))
    return np.array([JB, pvalue])


self_JBtest(ya)
self_JBtest(yb)
self_JBtest(yc)
self_JBtest(yd)

print('基于中位数的levene test P值：', stats.levene(ya, yb, yc, yd, center='median').pvalue)

predata = np.zeros([67, 3])

predata[:, 0] = data[:, idx]

for i in range(67):
    if (data[i, 18] == "高钾"):
        predata[i, 2] = 0
    else:
        predata[i, 2] = 1
    if (data[i, 16] == "无风化"):
        predata[i, 1] = 0
    else:
        predata[i, 1] = 1

predata = pd.DataFrame(predata, columns=['二氧化硅', '风化', '类型'])

model = ols("二氧化硅 ~风化+类型+风化:类型", data=predata)
mydata = model.fit()
print(anova_lm(mydata))

    \end{lstlisting}



    \textbf{\songti{第一问第二小问氧化钠分析}}
    \begin{lstlisting}[language=python]
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy
import scipy.stats as stats
from statsmodels.stats.anova import anova_lm
from statsmodels.formula.api import ols
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import statsmodels as sm

data = pd.read_excel("表1表2整合.xlsx")

data = data.values

a = 12  # 无风化 高钾
b = 23  # 无风化 铅钡
c = 6  # 风化 高钾
d = 26  # 风化 铅钡

alist = [0, 2, 3, 4, 5, 6, 7, 15, 16, 17, 18, 21]
blist = [20, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 39, 44, 45, 48, 49, 50, 51, 54, 56, 60, 63]
clist = [8, 11, 12, 14, 22, 28]
dlist = [1, 9, 10, 13, 19, 26, 27, 36, 38, 40, 41, 42, 43, 46, 47, 52, 53, 55, 57, 58, 59, 61, 62, 64, 65, 66]
#
# for i in range(data.shape[0]):
#     if(data[i,16]=="无风化" and data[i,18]=="高钾"):
#         a+=1
#         alist.append(i)
#     elif(data[i,16]=="无风化" and data[i,18]=="铅钡"):
#         b+=1
#         blist.append(i)
#     elif(data[i,16]=="风化" and data[i,18]=="高钾"):
#         c+=1
#         clist.append(i)
#     else:
#         d+=1
#         dlist.append(i)

ya = np.zeros(a)
yb = np.zeros(b)
yc = np.zeros(c)
yd = np.zeros(d)

idx = 2

for i in range(a):
    ya[i] = data[alist[i], idx]

for i in range(b):
    yb[i] = data[blist[i], idx]

for i in range(c):
    yc[i] = data[clist[i], idx]

for i in range(d):
    yd[i] = data[dlist[i], idx]

ya = np.sort(ya)
yb = np.sort(yb)
yc = np.sort(yc)
yd = np.sort(yd)


def self_JBtest(y):
    # 样本规模n
    n = y.size
    # for i in range(data.shape[0]):
    #     if(data[i,16]=="无风化"):
    #         n+=1
    y_ = y - y.mean()
    M2 = np.mean(y_ ** 2)

    skew = np.mean(y_ ** 3) / M2 ** 1.5
    krut = np.mean(y_ ** 4) / M2 ** 2

    #         wufenglist.append(i)
    #     else:
    #         m+=1
    #         fenglist.append(i)
    JB = n * (skew ** 2 / 6 + (krut - 3) ** 2 / 24)
    pvalue = 1 - stats.chi2.cdf(JB, df=2)
    print("JB检验：", stats.jarque_bera(y))
    return np.array([JB, pvalue])


self_JBtest(ya)
self_JBtest(yb)
self_JBtest(yc)
self_JBtest(yd)

print('基于中位数的levene test P值：', stats.levene(ya, yb, yc, yd, center='median').pvalue)

predata = np.zeros([67, 3])

predata[:, 0] = data[:, idx]

for i in range(67):
    if (data[i, 18] == "高钾"):
        predata[i, 2] = 0
    else:
        predata[i, 2] = 1
    if (data[i, 16] == "无风化"):
        predata[i, 1] = 0
    else:
        predata[i, 1] = 1

predata = pd.DataFrame(predata, columns=['氧化钠', '风化', '类型'])

model = ols("氧化钠 ~风化+类型+风化:类型", data=predata)
mydata = model.fit()
print(anova_lm(mydata))



gaojia=np.append(ya,yc)
qianbei=np.append(yb,yd)


fenghua=np.append(ya,yb)
wufenghua=np.append(yc,yd)


import scipy.stats as ss
from scipy.stats import ttest_ind
print("分为有无风化  组间比较  非参数检验")
print(ss.ranksums(wufenghua, fenghua))
print("无风化内部  做t检验")
print(ttest_ind(ya,yb))

self_JBtest(ya)
self_JBtest(yb)

self_JBtest(wufenghua)
self_JBtest(fenghua)

print(np.mean(ya),np.mean(yb),np.mean(ya)-np.mean(yb))

    \end{lstlisting}





    \textbf{\songti{第一问第三小问铅钡热图绘制}}
    \begin{lstlisting}[language=python]
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import spearmanr, pearsonr

plt.rcParams['font.sans-serif'] = ['FangSong']
plt.rcParams['axes.unicode_minus'] = False
z = pd.read_excel("铅钡总表.xlsx")
z = z.values

data = z[:, :]

res = pd.DataFrame(data, columns=[
    '二氧化硅', '氧化钠', '氧化钾', '氧化钙', '氧化镁', '氧化铝', '氧化铁', '氧化铜', '氧化铅',
    '氧化钡', '五氧化二磷', '氧化锶', '氧化锡', '二氧化硫'], dtype=np.float)

corr = res.corr(method='pearson')

sns.heatmap(corr, annot=True, vmax=1, vmin=-1, xticklabels=True, yticklabels=True,
            square=True, cmap="RdYlGn",annot_kws={"fontsize":7}).get_figure().savefig("temp.png",dpi=500,bbox_inches = 'tight')

plt.show()

    \end{lstlisting}




    \textbf{\songti{第一问第三小问铅钡氧化钠拟合}}
    \begin{lstlisting}[language=python]
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.optimize import curve_fit

plt.rcParams['font.sans-serif'] = ['FangSong']

data = pd.read_excel("铅钡氧化钠.xlsx")

data = data.values

y = data[:, 0]

y = y.flatten()

x = np.zeros([5, y.shape[0]])
for i in range(5):
    x[i] = data[:, i + 1]


def fun(x, px11, px22, px33, pt1, pt2, px1, px2, px3, px12, px13, px23, px00):
    x1 = x[0, :]
    x2 = x[1, :]
    x3 = x[2, :]
    t1 = x[3, :]
    t2 = x[4, :]

    return px11 * x1 ** 2 + px22 * x2 ** 2 \
           + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 \
           + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 \
           + px13 * x1 * x3 + px23 * x2 * x3 + px00


def funlin(x, pt1, pt2, px1, px2, px3, px00):
    x1 = x[0, :]
    x2 = x[1, :]
    x3 = x[2, :]
    t1 = x[3, :]
    t2 = x[4, :]
    return px1 * x1 + px2 * x2 + px3 * x3 + px00 + pt1 * t1 + pt2 * t2


popt, pcov = curve_fit(fun, x, y,method='trf')

px11, px22, px33, pt1, pt2, px1, px2, px3, px12, px13, px23, px00 = popt

y2 = np.zeros(y.shape[0])

former=[]
latter=[]


for i in range(y2.shape[0]):
    x1 = x[0, i]
    x2 = x[1, i]
    x3 = x[2, i]
    t1 = x[3, i]
    t2 = x[4, i]
    y2[i] = px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00
    if(t1==1 or t2==1):
        t1=0
        t2=0
        former.append(y[i])
        latter.append(px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00)


def __sst(y_no_fitting):
    # print(stats.pointbiserialr(x, y))
    # y是颜色
    # x是二值
    y_mean = sum(y_no_fitting) / len(y_no_fitting)
    # print(stats.pointbiserialr(x, y))
    # y是颜色
    # x是二值
    s_list = [(y - y_mean) ** 2 for y in y_no_fitting]
    sst = sum(s_list)
    return sst


def __ssr(y_fitting, y_no_fitting):

    y_mean = sum(y_no_fitting) / len(y_no_fitting)
    s_list = [(y - y_mean) ** 2 for y in y_fitting]
    # print(stats.pointbiserialr(x, y))
    # y是颜色
    # x是二值
    ssr = sum(s_list)
    return ssr


def __sse(y_fitting, y_no_fitting):

    s_list = [(y_fitting[i] - y_no_fitting[i]) ** 2 for i in range(len(y_fitting))]
    # print(stats.pointbiserialr(x, y))
    # y是颜色
    # x是二值
    sse = sum(s_list)
    return sse


def goodness_of_fit(y_fitting, y_no_fitting):

    SSR = __ssr(y_fitting, y_no_fitting)
    # print(stats.pointbiserialr(x, y))
    # y是颜色
    # x是二值
    SST = __sst(y_no_fitting)
    # print(stats.pointbiserialr(x, y))
    # y是颜色
    # x是二值
    rr = SSR / SST
    return rr


print(goodness_of_fit(y2, y))


print(former)
print(latter)

ans=np.zeros([len(former),2])

ans[:,0]=np.array(former)
ans[:,1]=np.array(latter)
np.savetxt("铅钡氧化钠预测.csv",ans,delimiter=',')

from scipy import stats

ci = 0.95
pp = (1. + ci) / 2.
nstd = stats.norm.ppf(pp)
perr = np.sqrt(np.diag(pcov))
popt_up = popt + nstd * perr
popt_dw = popt - nstd * perr
print("置信区间")
print(popt_dw)
print(popt_up)

print(popt)

    \end{lstlisting}


    \textbf{\songti{第一问第三小问高钾氧化铜拟合}}
    \begin{lstlisting}[language=python]
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.optimize import curve_fit

plt.rcParams['font.sans-serif'] = ['FangSong']

data = pd.read_excel("高钾氧化铜.xlsx")

data = data.values

y = data[:, 0]

y = y.flatten()

x = np.zeros([5, y.shape[0]])
for i in range(5):
    x[i] = data[:, i + 1]


def fun(x, px11, px22, px33, pt1, pt2, px1, px2, px3, px12, px13, px23, px00):
    x1 = x[0, :]
    x2 = x[1, :]
    x3 = x[2, :]
    t1 = x[3, :]
    t2 = x[4, :]

    return px11 * x1 ** 2 + px22 * x2 ** 2 \
           + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 \
           + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 \
           + px13 * x1 * x3 + px23 * x2 * x3 + px00


def funlin(x, pt1, pt2, px1, px2, px3, px00):
    x1 = x[0, :]
    x2 = x[1, :]
    x3 = x[2, :]
    t1 = x[3, :]
    t2 = x[4, :]
    return px1 * x1 + px2 * x2 + px3 * x3 + px00 + pt1 * t1 + pt2 * t2


popt, pcov = curve_fit(fun, x, y, method='trf')

px11, px22, px33, pt1, pt2, px1, px2, px3, px12, px13, px23, px00 = popt

y2 = np.zeros(y.shape[0])

former = []
latter = []

for i in range(y2.shape[0]):
    x1 = x[0, i]
    x2 = x[1, i]
    x3 = x[2, i]
    t1 = x[3, i]
    t2 = x[4, i]
    y2[ i] = px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00
    if (t1 == 1 or t2 == 1):
        t1 = 0
        t2 = 0
        former.append(y[i])
        latter.append(
            px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00)


def __sst(y_no_fitting):
    y_mean = sum(y_no_fitting) / len(y_no_fitting)
    # y2[ i] = px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00
    # if (t1 == 1 or t2 == 1):
    #     t1 = 0
    #     t2 = 0
    #     former.append(y[i])
    #     latter.append(
    #         px11 * x1 ** 2 +
    s_list = [(y - y_mean) ** 2 for y in y_no_fitting]
    sst = sum(s_list)
    return sst


def __ssr(y_fitting, y_no_fitting):
    # y2[ i] = px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00
    # if (t1 == 1 or t2 == 1):
    #     t1 = 0
    #     t2 = 0
    #     former.append(y[i])
    #     latter.append(
    #         px11 * x1 ** 2 +
    y_mean = sum(y_no_fitting) / len(y_no_fitting)
    s_list = [(y - y_mean) ** 2 for y in y_fitting]
    ssr = sum(s_list)
    return ssr


def __sse(y_fitting, y_no_fitting):
    s_list = [(y_fitting[i] - y_no_fitting[i]) ** 2 for i in range(len(y_fitting))]
    # y2[ i] = px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00
    # if (t1 == 1 or t2 == 1):
    #     t1 = 0
    #     t2 = 0
    #     former.append(y[i])
    #     latter.append(
    #         px11 * x1 ** 2 +
    sse = sum(s_list)
    return sse


def goodness_of_fit(y_fitting, y_no_fitting):
    SSR = __ssr(y_fitting, y_no_fitting)
    # y2[ i] = px11 * x1 ** 2 + px22 * x2 ** 2 + px33 * x3 ** 2 + pt1 * t1 + pt2 * t2 + px1 * x1 + px2 * x2 + px3 * x3 + px12 * x1 * x2 + px13 * x1 * x3 + px23 * x2 * x3 + px00
    # if (t1 == 1 or t2 == 1):
    #     t1 = 0
    #     t2 = 0
    #     former.append(y[i])
    #     latter.append(
    #         px11 * x1 ** 2 +
    SST = __sst(y_no_fitting)
    rr = SSR / SST
    return rr


print(goodness_of_fit(y2, y))

print(former)
print(latter)

ans = np.zeros([len(former), 2])

ans[:, 0] = np.array(former)
ans[:, 1] = np.array(latter)
np.savetxt("高钾氧化铜预测.csv", ans, delimiter=',')

print(popt)

    \end{lstlisting}


    \textbf{\songti{第二问第一小问逻辑回归}}
    \begin{lstlisting}[language=python]
# Create SVM classification object
import pandas as pd
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn import svm, linear_model

x=pd.read_excel("分类表格整理.xlsx")
x=x.values

y=pd.read_excel("分类表格结果.xlsx")
y=y.values
y=y.flatten()


x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,train_size=0.7)


model=linear_model.LogisticRegression(max_iter=1000)
model.fit(x_train,y_train)

y_test_predict=model.predict(x_test)

p_test=precision_score(y_test,y_test_predict)
r_test=recall_score(y_test,y_test_predict)
f1_test=f1_score(y_test,y_test_predict)
print(p_test,r_test,f1_test)

# print(model.coef_)
# print(model.intercept_)

rocy=model.predict_proba(x_test)
# print(rocy)


x3=pd.read_excel("问题3数据.xlsx")
x3=x3.values
pro3pre=model.predict(x3)
print(pro3pre)

print(metrics.log_loss(y_test,y_test_predict))
    \end{lstlisting}


    \textbf{\songti{轮廓系数计算}}
    \begin{lstlisting}[language=python]
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics


data = pd.read_excel("铅钡筛选后数据.xlsx")

data = data.values

data_array = data[:, 1:5]
model = AgglomerativeClustering(n_clusters=3, linkage='average')
mydata = data_array
y = data[:, 5]
print(model.fit_predict(data_array))

print("轮廓系数铅钡：", metrics.silhouette_score(data_array,model.fit_predict(data_array), metric='euclidean'))

    \end{lstlisting}


    \textbf{\songti{第二问第三小问敏感性分析}}
    \begin{lstlisting}[language=python]
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from sklearn.preprocessing import MinMaxScaler


data = pd.read_excel("铅钡筛选后数据.xlsx")

data = data.values

data_array = data[:, 1:5]
model = AgglomerativeClustering(n_clusters=3, linkage='average')
mydata = data_array
y = data[:, 5]
print(model.fit_predict(data_array))
anchor1 = [0, 11, 32]
anchor2 = [36]
anchor3 = [48, 43, 40]

idxlist1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
            31, 33, 34]

idxlist2 = [35, 37]

idxlist3 = [38, 39, 41, 42, 44, 45, 46, 47]

# idx=1 #
# idx=2   #提高50%  无变化
# idx=4    #提高50%  无变化
# idx=5    #提高50%  无变化
# idx=21    #提高50% 变化了

# idxlist=np.arange(35)
#
# idxlist=np.delete(idxlist,anchor1)


ylabel = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,
          2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

changesum = 0

# 可调参数
gaibianfudu = 0.9
zhelunzhibiaoxuhao = 0  # 用于选二氧化硅等 0表示二氧化硅  1表示氧化铅 2是五氧化二磷 3是氧化锶

print("种类1")
for idx in idxlist1:
    anchor_of_idx = 0  # 种类
    data = pd.read_excel("铅钡筛选后数据.xlsx")

    data = data.values

    data_array = data[:, 1:5]
    data_array_lat = data_array
    data_array_lat[idx, zhelunzhibiaoxuhao] = data_array_lat[idx, zhelunzhibiaoxuhao] * gaibianfudu

    model = AgglomerativeClustering(n_clusters=3, linkage='average')
    latlabel = model.fit_predict(data_array_lat)
    # print(latlabel)

    change = 1

    if (anchor_of_idx == 0):
        flag = 0
        if (latlabel[idx] == latlabel[anchor1[0]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor1[1]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor1[2]]):
            flag += 1
        if (flag >= 2):
            change = 0

    if (anchor_of_idx == 1):
        if (latlabel[idx] == latlabel[anchor2[0]]):
            change = 0

    if (anchor_of_idx == 2):
        flag = 0
        if (latlabel[idx] == latlabel[anchor3[0]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor3[1]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor3[2]]):
            flag += 1
        if (flag >= 2):
            change = 0
    changesum += change
    if (change == 1):
        print(idx)

print("种类2")
for idx in idxlist2:
    anchor_of_idx = 1  # 种类
    data = pd.read_excel("铅钡筛选后数据.xlsx")

    data = data.values

    data_array = data[:, 1:5]

    data_array_lat = data_array
    data_array_lat[idx, zhelunzhibiaoxuhao] = data_array_lat[idx, zhelunzhibiaoxuhao] * gaibianfudu

    model = AgglomerativeClustering(n_clusters=3, linkage='average')
    latlabel = model.fit_predict(data_array_lat)
    # print(latlabel)

    change = 1

    if (anchor_of_idx == 0):
        flag = 0
        if (latlabel[idx] == latlabel[anchor1[0]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor1[1]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor1[2]]):
            flag += 1
        if (flag >= 2):
            change = 0

    if (anchor_of_idx == 1):
        if (latlabel[idx] == latlabel[anchor2[0]]):
            change = 0

    if (anchor_of_idx == 2):
        flag = 0
        if (latlabel[idx] == latlabel[anchor3[0]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor3[1]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor3[2]]):
            flag += 1
        if (flag >= 2):
            change = 0
    changesum += change
    if (change == 1):
        print(idx)

print("种类3")
for idx in idxlist3:
    anchor_of_idx = 2  # 种类
    data = pd.read_excel("铅钡筛选后数据.xlsx")

    data = data.values

    data_array = data[:, 1:5]
    data_array_lat = data_array
    # print(data_array_lat)
    data_array_lat[idx, zhelunzhibiaoxuhao] = data_array_lat[idx, zhelunzhibiaoxuhao] * gaibianfudu

    model = AgglomerativeClustering(n_clusters=3, linkage='average')
    latlabel = model.fit_predict(data_array_lat)

    change = 1

    if (anchor_of_idx == 0):
        flag = 0
        if (latlabel[idx] == latlabel[anchor1[0]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor1[1]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor1[2]]):
            flag += 1
        if (flag >= 2):
            change = 0

    if (anchor_of_idx == 1):
        if (latlabel[idx] == latlabel[anchor2[0]]):
            change = 0

    if (anchor_of_idx == 2):
        flag = 0
        if (latlabel[idx] == latlabel[anchor3[0]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor3[1]]):
            flag += 1
        if (latlabel[idx] == latlabel[anchor3[2]]):
            flag += 1
        if (flag >= 2):
            change = 0
    changesum += change
    if (change == 1):
        print(idx)
print("改变量总和", changesum)

    \end{lstlisting}



    \textbf{\songti{第三问第一小问玻璃类别分类}}
    \begin{lstlisting}[language=python]
# Create SVM classification object
import pandas as pd
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn import svm, linear_model
import numpy as np

x = pd.read_excel("分类表格整理.xlsx")
x = x.values

y = pd.read_excel("分类表格结果.xlsx")
y = y.values
y = y.flatten()

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, train_size=0.7)

model = linear_model.LogisticRegression(max_iter=1000)
model.fit(x_train, y_train)

y_test_predict = model.predict(x_test)

p_test = precision_score(y_test, y_test_predict)
r_test = recall_score(y_test, y_test_predict)
f1_test = f1_score(y_test, y_test_predict)
print(p_test, r_test, f1_test)

# print(model.coef_)
# print(model.intercept_)

rocy = model.predict_proba(x_test)
# print(rocy)


x3 = pd.read_excel("问题3数据.xlsx")
x3 = x3.values
pro3pre = model.predict(x3)
print(pro3pre)

# print(metrics.log_loss(y_test,y_test_predict))

deltapre_proba = model.predict_proba(x_test)

probabi = np.zeros([21])
for i in range(21):
    probabi[i] = deltapre_proba[i, y_test[i]]

print(metrics.log_loss(y_test, probabi))

    \end{lstlisting}



    \textbf{\songti{第三问第二小问模型内部敏感性分析}}
    \begin{lstlisting}[language=python]
# Create SVM classification object
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn import svm, linear_model

x = pd.read_excel("分类表格整理.xlsx")
x = x.values

y = pd.read_excel("分类表格结果.xlsx")
y = y.values
y = y.flatten()

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, train_size=0.7)

cidx = np.linspace(0.000001, 100, 300)
res = []

for t in cidx:
    model = linear_model.LogisticRegression(C=t)
    model.fit(x_train, y_train)
    y_test_predict = model.predict(x_test)
    deltapre_proba=model.predict_proba(x_test)

    probabi=np.zeros([21])
    for i in range(21):
        probabi[i]=deltapre_proba[i,y_test[i]]

    res.append(metrics.log_loss(y_test, probabi))


plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

plt.xlabel('c值序号', fontsize=13)
plt.ylabel('logloss',fontsize=13)
plt.plot(np.arange(300),res)
plt.show()


tidx=np.linspace(0.000001, 100, 300)
rest=[]
for t in tidx:
    model = linear_model.LogisticRegression(tol=t)
    model.fit(x_train, y_train)
    y_test_predict = model.predict(x_test)
    deltapre_proba=model.predict_proba(x_test)

    probabi=np.zeros([21])
    for i in range(21):
        probabi[i]=deltapre_proba[i,y_test[i]]

    rest.append(metrics.log_loss(y_test, probabi))

plt.plot(np.arange(300),rest)
plt.xlabel('tol值序号', fontsize=13)
plt.ylabel('logloss',fontsize=13)
plt.show()


# model=linear_model.LogisticRegression(max_iter=1000)
# model.fit(x_train,y_train)

# y_test_predict = model.predict(x_test)
#
# print(metrics.log_loss(y_test, y_test_predict))

# p_test=precision_score(y_test,y_test_predict)
# r_test=recall_score(y_test,y_test_predict)
# f1_test=f1_score(y_test,y_test_predict)
# print(p_test,r_test,f1_test)

# print(model.coef_)
# print(model.intercept_)

# rocy=model.predict_proba(x_test)
# print(rocy)


# x3=pd.read_excel("问题3数据.xlsx")
# x3=x3.values
# pro3pre=model.predict(x3)
# print(pro3pre)

    \end{lstlisting}


    \textbf{\songti{第三问第二小问氧化铝输入敏感性分析}}
    \begin{lstlisting}[language=python]
# Create SVM classification object
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn import svm, linear_model

x = pd.read_excel("分类表格整理.xlsx")
x = x.values

y = pd.read_excel("分类表格结果.xlsx")
y = y.values
y = y.flatten()

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, train_size=0.7)

model = linear_model.LogisticRegression(max_iter=1000)
model.fit(x_train, y_train)

# y_test_predict=model.predict(x_test)

# p_test=precision_score(y_test,y_test_predict)
# r_test=recall_score(y_test,y_test_predict)
# f1_test=f1_score(y_test,y_test_predict)
# print(p_test,r_test,f1_test)

# print(model.coef_)
# print(model.intercept_)

# rocy=model.predict_proba(x_test)
# print(rocy)


x3 = pd.read_excel("问题3数据.xlsx")
x3 = x3.values
# pro3pre = model.predict(x3)
# print(pro3pre)
#
# print(metrics.log_loss(y_test,y_test_predict))


truelabel = [0, 1, 1, 1, 1, 0, 0, 1]

"""
二氧化硅 12
氧化钠 0.24
氧化钾 0.168
氧化钙 0.702
氧化镁
氧化铝(Al2O3)	
氧化铁(Fe2O3)	
氧化铜(CuO)	
氧化铅(PbO)	
氧化钡(BaO)	
五氧化二磷(P2O5)	
氧化锶(SrO)	
氧化锡(SnO2)	
二氧化硫(SO2)

"""

idx = 6
zengliang = 12

bound=100

deltalist = np.linspace(0, bound, bound)

losslist = []

for delta in deltalist:
    x3 = pd.read_excel("问题3数据.xlsx")
    x3 = x3.values
    myx = x3
    myx[:, idx] = myx[:, idx] + delta
    deltapre = model.predict(myx)
    deltapre_proba = model.predict_proba(myx)

    probabi = np.zeros([8])
    for i in range(8):
        probabi[i] = deltapre_proba[i, truelabel[i]]

    losslist.append(metrics.log_loss(truelabel, probabi))

plt.plot(deltalist,losslist)

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

plt.xlabel('氧化铝增量值', fontsize=13)
plt.ylabel('logloss',fontsize=13)
plt.show()
    \end{lstlisting}


    \textbf{\songti{第四问第一小问皮尔逊相关系数检验}}
    \begin{lstlisting}[language=python]
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import spearmanr, pearsonr

plt.rcParams['font.sans-serif'] = ['FangSong']
plt.rcParams['axes.unicode_minus'] = False
z = pd.read_excel("铅钡总表.xlsx")
z = z.values

data = z[:, :]

res = pd.DataFrame(data, columns=[
    '二氧化硅', '氧化钠', '氧化钾', '氧化钙', '氧化镁', '氧化铝', '氧化铁', '氧化铜', '氧化铅',
    '氧化钡', '五氧化二磷', '氧化锶', '氧化锡', '二氧化硫'], dtype=np.float)

corr = res.corr(method='pearson')

sns.heatmap(corr, annot=True, vmax=1, vmin=-1, xticklabels=True, yticklabels=True,
            square=True, cmap="RdYlGn",annot_kws={"fontsize":7}).get_figure().savefig("temp.png",dpi=500,bbox_inches = 'tight')

# plt.show()


name = ['二氧化硅', '氧化钠', '氧化钾', '氧化钙', '氧化镁', '氧化铝', '氧化铁', '氧化铜', '氧化铅',
        '氧化钡', '五氧化二磷', '氧化锶', '氧化锡', '二氧化硫']

# print(pearsonr(res['过滤阻力'], res['透气性']))

matriccor=np.zeros([14,14])
for n in range(14):
    for m in range(n + 1, 14):
        # print(name[n],name[m])
        # print(pearsonr(res[name[n]], res[name[m]]))
        _,pvalue=pearsonr(res[name[n]], res[name[m]])
        matriccor[n,m]=pvalue

np.savetxt("铅钡热图p值.csv",matriccor,delimiter=',')
    \end{lstlisting}


    \textbf{\songti{第四问第二小问z检验}}
    \begin{lstlisting}[language=python]
import math

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import spearmanr, pearsonr
from scipy.stats import norm

plt.rcParams['font.sans-serif'] = ['FangSong']
plt.rcParams['axes.unicode_minus'] = False
z = pd.read_excel("高钾总表.xlsx")
z = z.values

data = z[:, :]

res = pd.DataFrame(data, columns=[
    '二氧化硅', '氧化钠', '氧化钾', '氧化钙', '氧化镁', '氧化铝', '氧化铁', '氧化铜', '氧化铅',
    '氧化钡', '五氧化二磷', '氧化锶', '氧化锡', '二氧化硫'], dtype=np.float)

corrgaojia = res.corr(method='pearson')
corrgaojia = corrgaojia.values
z = pd.read_excel("铅钡总表.xlsx")
z = z.values

data = z[:, :]

res = pd.DataFrame(data, columns=[
    '二氧化硅', '氧化钠', '氧化钾', '氧化钙', '氧化镁', '氧化铝', '氧化铁', '氧化铜', '氧化铅',
    '氧化钡', '五氧化二磷', '氧化锶', '氧化锡', '二氧化硫'], dtype=np.float)

corrqianbei = res.corr(method='pearson')

corrqianbei = corrqianbei.values
zpvalue = np.zeros([14, 14])

for i in range(14):
    for j in range(14):
        if (i != j):
            gaojia = corrgaojia[i, j]
            qianbei = corrqianbei[i, j]

            r1 = gaojia
            n1 = 18
            r2 = qianbei
            n2 = 49

            z1 = 0.5 * math.log((1 + r1) / (1 - r1))
            z2 = 0.5 * math.log((1 + r2) / (1 - r2))

            ddiff = z1 - z2
            SEddiff = math.sqrt(1 / (n1 - 3) + 1 / (n2 - 3))

            zvalue = ddiff / SEddiff
            pvalue = 2 * (1 - norm.cdf(abs(zvalue)))
            zpvalue[i, j] = pvalue
np.savetxt("z检验p值结果.csv",zpvalue,delimiter=',')

    \end{lstlisting}